{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入必要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from d2l import torch as d2l\n",
    "import pandas as pd # 读取数据\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取并加载数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_array(data_arrays, batch_size, is_train=True):\n",
    "    \"\"\"\n",
    "    构造一个 PyTorch 数据迭代器。\n",
    "\n",
    "    根据给定的数据数组创建一个 `DataLoader`，用于批量加载数据，支持随机打乱数据顺序。\n",
    "\n",
    "    参数:\n",
    "        data_arrays (tuple[torch.Tensor, ...]): 包含特征和标签的元组，每个元素是一个 `torch.Tensor`。\n",
    "        batch_size (int): 每个小批量的样本数量。\n",
    "        is_train (bool): 是否将数据打乱（`True` 表示训练模式，数据会随机打乱；`False` 表示测试模式，数据按顺序加载）。\n",
    "\n",
    "    返回:\n",
    "        torch.utils.data.DataLoader: 一个数据加载器对象，用于按批量加载数据。\n",
    "    \"\"\"\n",
    "    # 使用 TensorDataset 将特征和标签封装成一个数据集对象\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "\n",
    "    # 创建 DataLoader，指定批量大小和是否随机打乱数据\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检验迭代器是否正常工作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.4364,  0.2379, -0.8663],\n",
       "         [-0.4827, -0.5954,  0.3239],\n",
       "         [-0.8548,  0.3612,  0.9981],\n",
       "         [-0.2216,  0.8152,  1.5884],\n",
       "         [ 0.5606, -2.8520,  0.1266],\n",
       "         [-0.6191, -0.4520, -0.0456],\n",
       "         [-0.2312, -1.1332,  0.2500],\n",
       "         [ 1.0375,  1.3158,  0.8466],\n",
       "         [ 0.9669, -0.8326,  1.0349],\n",
       "         [-0.4858, -1.0137,  1.8953]]),\n",
       " tensor([[-5.7090, -0.7990],\n",
       "         [ 0.8442,  2.0223],\n",
       "         [ 3.8831, -1.2231],\n",
       "         [ 8.4354, -2.7539],\n",
       "         [ 1.8268,  9.6846],\n",
       "         [-1.5062,  1.5518],\n",
       "         [ 0.9539,  3.8662],\n",
       "         [ 6.8066, -4.4758],\n",
       "         [ 7.7479,  2.8347],\n",
       "         [ 9.6270,  3.4516]])]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "data_iter = load_array((features, labels), batch_size)\n",
    "\n",
    "next(iter(data_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义线性模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = 3\n",
    "out_features = 2\n",
    "net = nn.Sequential(nn.Linear(in_features, out_features))\n",
    "# nn是神经网络的缩写\n",
    "# Sequential是一个有序容器，网络层将按照在传入Sequential的顺序依次被添加到计算图中执行\n",
    "# Linear是一个全连接层，它接收一个输入张量，然后计算输出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初始化模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0.])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data.normal_(0, 0.01)\n",
    "net[0].bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义优化算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = torch.optim.SGD(net.parameters(), lr=0.03)\n",
    "# parameters()返回一个包含模型所有参数的迭代器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.000100\n",
      "epoch 2, loss 0.000100\n",
      "epoch 3, loss 0.000100\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3  # 设置训练的总轮数\n",
    "for epoch in range(num_epochs):  # 遍历每一轮训练\n",
    "    for X, y in data_iter:  # 遍历每个小批量数据\n",
    "        # 计算当前批量数据的损失\n",
    "        l = loss(net(X), y)\n",
    "\n",
    "        # 梯度清零，防止累积\n",
    "        trainer.zero_grad()  \n",
    "\n",
    "        # 计算梯度\n",
    "        l.backward()  \n",
    "\n",
    "        # 根据梯度更新参数\n",
    "        trainer.step()  \n",
    "\n",
    "    # 在每轮训练结束后，计算整个数据集上的损失\n",
    "    l = loss(net(features), labels)  \n",
    "\n",
    "    # 打印当前轮次和对应的损失\n",
    "    print(f'epoch {epoch + 1}, loss {l:f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
