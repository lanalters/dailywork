{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入必要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from d2l import torch as d2l\n",
    "import pandas as pd # 读取数据\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_w1 = torch.tensor([2, -3.4, 5.6])\n",
    "true_w2 = torch.tensor([4.2, 2.1, -3.1])\n",
    "true_b1 = 4.2\n",
    "true_b2 = 4.2\n",
    "\n",
    "# 生成数据集\n",
    "# 3 个特征，2 个标签\n",
    "# 1000 个样本\n",
    "in_features = 3\n",
    "out_features = 2\n",
    "num_examples = 1000\n",
    "\n",
    "\n",
    "# 生成特征矩阵 X，正态分布随机值，形状为 (num_examples, n_features)\n",
    "features = torch.normal(0, 1, (num_examples, in_features))\n",
    "# features 是一个 (num_examples, in_features) 的矩阵\n",
    "y1 = torch.matmul(features, true_w1) + true_b1\n",
    "y2 = torch.matmul(features, true_w2) + true_b2\n",
    "# 添加随机噪声，模拟真实数据中的误差\n",
    "y1 += torch.normal(0, 0.01, y1.shape)\n",
    "y2 += torch.normal(0, 0.01, y2.shape)\n",
    "\n",
    "labels = torch.stack((y1, y2), 1)\n",
    "# labels 是一个 (num_examples, out_features) 的矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取并加载数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_array(data_arrays, batch_size, is_train=True):\n",
    "    \"\"\"\n",
    "    构造一个 PyTorch 数据迭代器。\n",
    "\n",
    "    根据给定的数据数组创建一个 `DataLoader`，用于批量加载数据，支持随机打乱数据顺序。\n",
    "\n",
    "    参数:\n",
    "        data_arrays (tuple[torch.Tensor, ...]): 包含特征和标签的元组，每个元素是一个 `torch.Tensor`。\n",
    "        batch_size (int): 每个小批量的样本数量。\n",
    "        is_train (bool): 是否将数据打乱（`True` 表示训练模式，数据会随机打乱；`False` 表示测试模式，数据按顺序加载）。\n",
    "\n",
    "    返回:\n",
    "        torch.utils.data.DataLoader: 一个数据加载器对象，用于按批量加载数据。\n",
    "    \"\"\"\n",
    "    # 使用 TensorDataset 将特征和标签封装成一个数据集对象\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "\n",
    "    # 创建 DataLoader，指定批量大小和是否随机打乱数据\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检验迭代器是否正常工作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.3469, -0.5399, -0.5998],\n",
       "         [-0.9775, -0.8029,  0.0220],\n",
       "         [-1.2920,  1.0517,  0.2393],\n",
       "         [ 0.8075,  0.4184, -0.5507],\n",
       "         [ 2.1325,  0.8381, -0.9595],\n",
       "         [ 0.4157, -0.7942,  1.2377],\n",
       "         [ 0.4274,  0.6164, -1.3207],\n",
       "         [-0.3655, -0.7261, -0.7089],\n",
       "         [ 0.6097, -1.4632,  0.6271],\n",
       "         [-0.8005,  0.2740,  1.0022]]),\n",
       " tensor([[ 1.9755,  3.4669],\n",
       "         [ 5.0889, -1.6675],\n",
       "         [-0.6047,  0.2288],\n",
       "         [ 1.2882, 10.1939],\n",
       "         [ 0.2430, 17.8943],\n",
       "         [14.6527,  0.4284],\n",
       "         [-4.4460, 11.3782],\n",
       "         [ 1.9579,  3.3265],\n",
       "         [13.9044,  1.7502],\n",
       "         [ 7.2685, -1.6833]])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 10\n",
    "data_iter = load_array((features, labels), batch_size)\n",
    "\n",
    "next(iter(data_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义线性模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = 3\n",
    "out_features = 2\n",
    "net = nn.Sequential(nn.Linear(in_features, out_features))\n",
    "# nn是神经网络的缩写\n",
    "# Sequential是一个有序容器，网络层将按照在传入Sequential的顺序依次被添加到计算图中执行\n",
    "# Linear是一个全连接层，它接收一个输入张量，然后计算输出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初始化模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.data.normal_(0, 0.01)\n",
    "net[0].bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义优化算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = torch.optim.SGD(net.parameters(), lr=0.03)\n",
    "# parameters()返回一个包含模型所有参数的迭代器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.000095\n",
      "epoch 2, loss 0.000095\n",
      "epoch 3, loss 0.000095\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3  # 设置训练的总轮数\n",
    "for epoch in range(num_epochs):  # 遍历每一轮训练\n",
    "    for X, y in data_iter:  # 遍历每个小批量数据\n",
    "        # 计算当前批量数据的损失\n",
    "        l = loss(net(X), y)\n",
    "\n",
    "        # 梯度清零，防止累积\n",
    "        trainer.zero_grad()  \n",
    "\n",
    "        # 计算梯度\n",
    "        l.backward()  \n",
    "\n",
    "        # 根据梯度更新参数\n",
    "        trainer.step()  \n",
    "\n",
    "    # 在每轮训练结束后，计算整个数据集上的损失\n",
    "    l = loss(net(features), labels)  \n",
    "\n",
    "    # 打印当前轮次和对应的损失\n",
    "    print(f'epoch {epoch + 1}, loss {l:f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最后比较一下训练的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1的估计误差： tensor([0.0008, 0.0003, 0.0002])\n",
      "w2的估计误差： tensor([-3.5286e-05,  2.5439e-04,  2.0528e-04])\n",
      "b的估计误差： tensor(2.0504e-05)\n",
      "b的估计误差： tensor(-0.0004)\n"
     ]
    }
   ],
   "source": [
    "w = net[0].weight.data\n",
    "# w 是一个形状为 (out_features, in_features) 的张量\n",
    "print('w1的估计误差：', true_w1 - w[0].reshape(in_features))\n",
    "print('w2的估计误差：', true_w2 - w[1].reshape(in_features))\n",
    "b = net[0].bias.data\n",
    "print('b的估计误差：', true_b1 - b[0])\n",
    "print('b的估计误差：', true_b2 - b[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
