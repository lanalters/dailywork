{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入必要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from d2l import torch as d2l\n",
    "import pandas as pd # 读取数据\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取并加载数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据集的可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义迭代器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_array(data_arrays, batch_size, is_train=True):\n",
    "    \"\"\"\n",
    "    构造一个 PyTorch 数据迭代器。\n",
    "\n",
    "    根据给定的数据数组创建一个 `DataLoader`，用于批量加载数据，支持随机打乱数据顺序。\n",
    "\n",
    "    参数:\n",
    "        data_arrays (tuple[torch.Tensor, ...]): 包含特征和标签的元组，每个元素是一个 `torch.Tensor`。\n",
    "        batch_size (int): 每个小批量的样本数量。\n",
    "        is_train (bool): 是否将数据打乱（`True` 表示训练模式，数据会随机打乱；`False` 表示测试模式，数据按顺序加载）。\n",
    "\n",
    "    返回:\n",
    "        torch.utils.data.DataLoader: 一个数据加载器对象，用于按批量加载数据。\n",
    "    \"\"\"\n",
    "    # 使用 TensorDataset 将特征和标签封装成一个数据集对象\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "\n",
    "    # 创建 DataLoader，指定批量大小和是否随机打乱数据\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 检验迭代器是否正常工作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "data_iter = load_array((features, labels), batch_size)\n",
    "\n",
    "next(iter(data_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义线性模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = 2\n",
    "out_features = 1\n",
    "net = nn.Sequential(nn.Linear(in_features, out_features))\n",
    "# nn是神经网络的缩写\n",
    "# Sequential是一个有序容器，网络层将按照在传入Sequential的顺序依次被添加到计算图中执行\n",
    "# Linear是一个全连接层，它接收一个输入张量，然后计算输出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初始化模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net[0].weight.data.normal_(0, 0.01)\n",
    "net[0].bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义优化算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = torch.optim.SGD(net.parameters(), lr=0.03)\n",
    "# parameters()返回一个包含模型所有参数的迭代器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_iter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m  \u001b[38;5;66;03m# 设置训练的总轮数\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):  \u001b[38;5;66;03m# 遍历每一轮训练\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m X, y \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdata_iter\u001b[49m:  \u001b[38;5;66;03m# 遍历每个小批量数据\u001b[39;00m\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;66;03m# 计算当前批量数据的损失\u001b[39;00m\n\u001b[1;32m      5\u001b[0m         l \u001b[38;5;241m=\u001b[39m loss(net(X), y)  \n\u001b[1;32m      7\u001b[0m         \u001b[38;5;66;03m# 梯度清零，防止累积\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_iter' is not defined"
     ]
    }
   ],
   "source": [
    "num_epochs = 3  # 设置训练的总轮数\n",
    "for epoch in range(num_epochs):  # 遍历每一轮训练\n",
    "    for X, y in data_iter:  # 遍历每个小批量数据\n",
    "        # 计算当前批量数据的损失\n",
    "        l = loss(net(X), y)  \n",
    "\n",
    "        # 梯度清零，防止累积\n",
    "        trainer.zero_grad()  \n",
    "\n",
    "        # 计算梯度\n",
    "        l.backward()  \n",
    "\n",
    "        # 根据梯度更新参数\n",
    "        trainer.step()  \n",
    "\n",
    "    # 在每轮训练结束后，计算整个数据集上的损失\n",
    "    l = loss(net(features), labels)  \n",
    "\n",
    "    # 打印当前轮次和对应的损失\n",
    "    print(f'epoch {epoch + 1}, loss {l:f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
